import os  # Operaciones del sistema operativo (no se usa en este script pero es comÃºn tenerlo)
import torch  # LibrerÃ­a principal para deep learning
import torch.nn as nn  # SubmÃ³dulo para redes neuronales
import torch.optim as optim  # SubmÃ³dulo para optimizadores
from torchvision import datasets, transforms, models  # Utilidades para imÃ¡genes y modelos preentrenados
from torch.utils.data import DataLoader, random_split  # Utilidades para cargar y dividir datasets

# ================================
# CONFIGURACIÃ“N DE PARÃMETROS
# ================================
DATASET_DIR = r"C:\Users\raven\Proyecto_de_profundizacion_traduccion_de_senas\Traductor_de_senas\datasets"  # Ruta del dataset
BATCH_SIZE = 32  # TamaÃ±o de lote para entrenamiento y validaciÃ³n
EPOCHS = 15  # NÃºmero de Ã©pocas de entrenamiento
LR = 0.001  # Tasa de aprendizaje para el optimizador
VAL_SPLIT = 0.2  # Porcentaje de datos para validaciÃ³n (20%)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Usa GPU si estÃ¡ disponible, si no CPU
print(f"âš¡ Entrenando en: {device}")  # Muestra el dispositivo usado

# ================================
# TRANSFORMACIONES DE DATOS
# ================================
data_transforms = transforms.Compose([  # ComposiciÃ³n de transformaciones para las imÃ¡genes
    transforms.Resize((224, 224)),  # Redimensiona la imagen a 224x224 pÃ­xeles
    transforms.RandomHorizontalFlip(),  # Aplica flip horizontal aleatorio
    transforms.RandomRotation(10),  # Aplica rotaciÃ³n aleatoria de hasta 10 grados
    transforms.ToTensor(),  # Convierte la imagen a tensor
    transforms.Normalize([0.485, 0.456, 0.406],  # Normaliza usando la media de ImageNet
                         [0.229, 0.224, 0.225])  # y la desviaciÃ³n estÃ¡ndar de ImageNet
])

# ================================
# CARGA DEL DATASET
# ================================
dataset = datasets.ImageFolder(DATASET_DIR, transform=data_transforms)  # Carga las imÃ¡genes y aplica las transformaciones

# Divide el dataset en entrenamiento y validaciÃ³n
val_size = int(len(dataset) * VAL_SPLIT)  # Calcula el tamaÃ±o del conjunto de validaciÃ³n
train_size = len(dataset) - val_size  # Calcula el tamaÃ±o del conjunto de entrenamiento
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])  # Divide el dataset

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)  # Crea el DataLoader para entrenamiento
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)  # Crea el DataLoader para validaciÃ³n

print(f"ğŸ“‚ Total imÃ¡genes: {len(dataset)}")  # Muestra el total de imÃ¡genes
print(f"   ğŸ‹ï¸â€â™‚ï¸ Train: {len(train_dataset)}")  # Muestra el total de imÃ¡genes de entrenamiento
print(f"   âœ… Val: {len(val_dataset)}")  # Muestra el total de imÃ¡genes de validaciÃ³n
print(f"   ğŸ“š Clases: {len(dataset.classes)} -> {dataset.classes}")  # Muestra las clases detectadas

# ================================
# DEFINICIÃ“N DEL MODELO
# ================================
model = models.resnet18(weights="IMAGENET1K_V1")  # Carga el modelo ResNet18 preentrenado en ImageNet
num_ftrs = model.fc.in_features  # Obtiene el nÃºmero de caracterÃ­sticas de entrada de la capa final
model.fc = nn.Linear(num_ftrs, len(dataset.classes))  # Reemplaza la capa final para que tenga tantas salidas como clases
model = model.to(device)  # Mueve el modelo al dispositivo seleccionado (GPU o CPU)

criterion = nn.CrossEntropyLoss()  # Define la funciÃ³n de pÃ©rdida (entropÃ­a cruzada)
optimizer = optim.Adam(model.parameters(), lr=LR)  # Define el optimizador Adam

# Inicializa la mejor precisiÃ³n en validaciÃ³n
best_acc = 0.0

# ================================
# ENTRENAMIENTO Y VALIDACIÃ“N
# ================================
for epoch in range(EPOCHS):  # Bucle principal de entrenamiento por Ã©pocas
    print(f"\nğŸ“Œ Epoch {epoch+1}/{EPOCHS}")  # Muestra la Ã©poca actual

    # ---- Entrenamiento ----
    model.train()  # Pone el modelo en modo entrenamiento
    running_loss, running_corrects = 0.0, 0  # Inicializa acumuladores de pÃ©rdida y aciertos
    for inputs, labels in train_loader:  # Itera sobre los lotes de entrenamiento
        inputs, labels = inputs.to(device), labels.to(device)  # Mueve los datos al dispositivo

        optimizer.zero_grad()  # Reinicia los gradientes
        outputs = model(inputs)  # Calcula la salida del modelo
        loss = criterion(outputs, labels)  # Calcula la pÃ©rdida
        loss.backward()  # Calcula los gradientes
        optimizer.step()  # Actualiza los pesos

        _, preds = torch.max(outputs, 1)  # Obtiene la clase predicha
        running_loss += loss.item() * inputs.size(0)  # Acumula la pÃ©rdida
        running_corrects += torch.sum(preds == labels.data)  # Acumula los aciertos

    epoch_loss = running_loss / train_size  # Calcula la pÃ©rdida promedio de la Ã©poca
    epoch_acc = running_corrects.double() / train_size  # Calcula la precisiÃ³n promedio de la Ã©poca
    print(f"   ğŸ‹ï¸â€â™‚ï¸ Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")  # Muestra mÃ©tricas de entrenamiento

    # ---- ValidaciÃ³n ----
    model.eval()  # Pone el modelo en modo evaluaciÃ³n
    val_loss, val_corrects = 0.0, 0  # Inicializa acumuladores de pÃ©rdida y aciertos para validaciÃ³n
    with torch.no_grad():  # Desactiva el cÃ¡lculo de gradientes (mÃ¡s eficiente)
        for inputs, labels in val_loader:  # Itera sobre los lotes de validaciÃ³n
            inputs, labels = inputs.to(device), labels.to(device)  # Mueve los datos al dispositivo
            outputs = model(inputs)  # Calcula la salida del modelo
            loss = criterion(outputs, labels)  # Calcula la pÃ©rdida

            _, preds = torch.max(outputs, 1)  # Obtiene la clase predicha
            val_loss += loss.item() * inputs.size(0)  # Acumula la pÃ©rdida
            val_corrects += torch.sum(preds == labels.data)  # Acumula los aciertos

    val_loss /= val_size  # Calcula la pÃ©rdida promedio de validaciÃ³n
    val_acc = val_corrects.double() / val_size  # Calcula la precisiÃ³n promedio de validaciÃ³n
    print(f"   âœ… Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}")  # Muestra mÃ©tricas de validaciÃ³n

    # Guardar mejor modelo
    if val_acc > best_acc:  # Si la precisiÃ³n de validaciÃ³n es la mejor hasta ahora
        best_acc = val_acc  # Actualiza la mejor precisiÃ³n
        torch.save(model.state_dict(), "mejor_modelo_resnet18.pth")  # Guarda los pesos del modelo
        print("   ğŸ’¾ Modelo guardado (mejor hasta ahora)")  # Informa que se guardÃ³ el modelo

print(f"\nğŸ¯ Entrenamiento terminado. Mejor accuracy en validaciÃ³n: {best_acc:.4f}")  # Muestra la mejor precisiÃ³n final
